#! /bin/env python
#! /usr/bin/env python2.7
import time
starttime = time.time()
import sys
import argparse
import multiprocessing
import re
from math import sqrt
import os
import random
from tnt.lib import *

MASTER = os.getppid()

def main():
#--------------------------MAIN PROGRAM-----------------------------

#	commandline argument parsing
	indata = getindata()
	indata.logfile.write('Start.\n')
	indata.logfile.write('Running script '+time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())+'.\n')
	indata.logfile.write('Master process id='+str(MASTER)+'\n')
	indata.logfile.write('cmd: '+' '.join(sys.argv)+'\n')
	if indata.selftest: indata.logfile.write('Running in selftest mode no real data will be analyzed.\n')
	
	# get the readcount
	indata.logfile.write('Getting readcount ... ')
	numreads=bufcount(indata.reads1.name)/4
	indata.logfile.write(str(numreads)+' read pairs in fastq files.\n');

	# calculate the number of reads to process
	indata.reads2process = numreads
	if indata.skip: indata.reads2process -= indata.skip
	if indata.stop: indata.reads2process = indata.stop
	if indata.n:    indata.reads2process = indata.n
	
	#deciding if to run multiprocessing or single process for debbuging
	if indata.debug: #single process // serial
		
		results=[] # create holder for processed reads
		indata.logfile.write('Part1: Running in debug mode searching for threads ...\n')
		
		progress = Progress(indata.reads2process, logfile=indata.logfile) # creates a progress "bar" thingy
		
		#itarate through reads and do the "magicFunction"
		with progress:
			for tmp in getPairs(indata):
				progress.update()
				results.append(magicFunction(tmp))
		indata.logfile.write('Part1: search finished\n')
	else: # multiple processes in parallel
		#create worker pool that iterates through the reads and does the "magicFunction" and sends results to "results"
		WorkerPool = multiprocessing.Pool(indata.cpus,maxtasksperchild=100)
		if not indata.keeporder: results = WorkerPool.imap_unordered(magicFunction,getPairs(indata),chunksize=10)
		if indata.keeporder:     results = WorkerPool.imap(magicFunction,getPairs(indata),chunksize=10)

	# output log message about whats happening
	if not indata.debug: indata.logfile.write('Part1: running in multiproccessing mode using '+str(indata.cpus)+' processes  ...\n')
	else: indata.logfile.write('Part2: running the multiprocessing results handeling in serial\n')
	
	#set initial values of counters etc
	counter = 0
	last = [0,starttime,counter]
	combos = {}
	threads=0
	identifiable=0
	bothidentifiable=0
	same = 0
	notsame = 0
	
	#create progress "bar"
	progress1 = Progress(indata.reads2process, logfile=indata.logfile)
	
	# iterate through the results
	TNTdata = {}
	for var_id in VARIATIONINFO:TNTdata[var_id] = Variation(var_id)
	with progress1:
		for pair in results:
			
			# increment counter and update progressbar
			counter += 1
			progress1.update()
			
			# go through the tnt threads found within the read pair
			for thread in pair.threads:
				
				threads+=1 # increment counter of analyzed threads
				
				# increment counter of specific combinations
				try:		combos[str(thread.extprimer)+'-'+str(thread.tjprimer)]+=1
				except KeyError:combos[str(thread.extprimer)+'-'+str(thread.tjprimer)]=1
				
				# dump to file
				if indata.sample:
					f = open(indata.sample+'.threads/'+str(thread.extprimer)+'-'+str(thread.tjprimer)+'.txt','a')
					f.write(thread.seq+'\n')
					f.close
				
				# check what parts were found within the thread and update counters
				if thread.tjprimer or thread.extprimer:
					identifiable+=1
					
					if thread.tjprimer and thread.extprimer:
						bothidentifiable+=1
					
						if thread.tjprimer == thread.extprimer:
							same+=1
							
							# add the goodones to list so that we ca calculate AF later on
							try:TNTdata[thread.tjprimer].add(thread)
							except KeyError:
								TNTdata[thread.tjprimer] = Variation(thread.tjprimer)
								TNTdata[thread.tjprimer].add(thread)
					
						else:
							notsame += 1
	
	for combo,count in combos.iteritems():
		pass#indata.outfile.write( str(count)+ '\t'+str(round(100*float(count)/(threads),2))+'\t'+ combo+'\n')
	indata.logfile.write('Part 1 finished in '+str(round(time.time()-starttime,2))+'s, '+str(counter)+' reads processed,\n '+str(threads)+' ('+str(int(round(100*float(threads)/(counter*2))))+'%) threads,\n whereof '+str(identifiable)+' ('+str(int(round(100*float(identifiable)/threads)))+'%) were identifiable \nwhereof '+str(bothidentifiable)+' ('+str(int(round(100*float(bothidentifiable)/identifiable)))+'%) were both primers identifiable \nwhereof '+str(same)+' ('+str(int(round(100*float(same)/bothidentifiable)))+'%) were both primers are the same (vs '+str(notsame)+' ('+str(int(round(100*float(notsame)/bothidentifiable)))+'%) unspecific products).\n')
	indata.logfile.write('\n')

	indata.logfile.write('Part2: for each variation calculate allel frequencies and "genotype" ... \n')
	total_vars = len(TNTdata.keys())
	
	#deciding if to run multiprocessing or single process for debbuging
	if indata.debug: #single process // serial
		
		results=[] # create holder for processed reads
		indata.logfile.write('Part1: Running in debug mode ie serial ...\n')
		
		progress = Progress(total_vars, logfile=indata.logfile) # creates a progress "bar" thingy
		
		#itarate through reads and do the "magicFunction"
		with progress:
			for variation in yielder(TNTdata):
				results.append(magicFunction2(variation))
				progress.update()

	else: # multiple processes in parallel
		#create worker pool that iterates through the reads and does the "magicFunction" and sends results to "results"
		WorkerPool = multiprocessing.Pool(indata.cpus,maxtasksperchild=10)
		if not indata.keeporder: results = WorkerPool.imap_unordered(magicFunction2,yielder(TNTdata),chunksize=2)
		if indata.keeporder:     results = WorkerPool.imap(          magicFunction2,yielder(TNTdata),chunksize=2)

	progress = Progress(total_vars,unit='SNP')
	with progress:
		for variation in results:
			sys.stdout.write(variation.output)
			progress.update()
#--------------------------MAIN PROGRAM END-------------------------

#--------------------- Functions, Subroutines and classes --------------------	
def yielder(TNTdata):
	for var_id in VARIATIONINFO:
		yield TNTdata[var_id]

def magicFunction2(variation):
	variation.alignthreads()
	return variation

def getindata():
	argparser = argparse.ArgumentParser(	description='Analysis of Tnt data from the miseq.',
											formatter_class=argparse.RawTextHelpFormatter,
										)
	argparser.add_argument(	'--debug',		dest='debug', 			action='store_true', 			required=False,	default=False,	help='debug (run as regular single process python script).')
	argparser.add_argument(	'--selftest',		dest='selftest', 		action='store_true', 			required=False,	default=False,	help='Run a selftest to see that reads are correctly classified.')
	argparser.add_argument(	'-skip',		dest='skip',	metavar='N',				type=int,	required=False,	default=0,	help='skip the first N read pairs in files (default 0).')
	argparser.add_argument(	'-stop',		dest='stop',	metavar='N',				type=int,	required=False,	default=0,	help='stop after N read pairs, set to 0 to disable (default 0).')
	argparser.add_argument(	'-r1',			dest='reads1',	metavar='FILE',				type=file,	required=True, 			help='indata "fastq"-file read1.')
	argparser.add_argument(	'-r2',			dest='reads2',	metavar='FILE',				type=file,	required=True,	default=None,	help='indata "fastq"-file read2.')
	argparser.add_argument(	'-p',			dest='cpus',	metavar='N',				type=int,	required=False,	default=1,	help='The number of processes to start (default 1).')
	argparser.add_argument(	'-o',			dest='outfile',	metavar='outfile',			type=str,	required=False,	default=False,	help='Print output to outfile (default stdout).')
	argparser.add_argument(	'-l',			dest='logfile',	metavar='logfile',			type=str,	required=False,	default=False,	help='Print log messages to logfile (default stderr).')
	argparser.add_argument(	'-sample',		dest='sample',	metavar='str',				type=str,	required=False,	default=False,	help='Sample name to use for out and logfile namin (default Disabled).')
	argparser.add_argument(	'-random',		dest='n',	metavar='N',				type=int,	required=False,	default=0,	help='Use a random subset of N read pairs, this option is slower (default 0 = off). Can not be used in combination with "-skip" or "-stop"')
	argparser.add_argument(	'--keeporder',		dest='keeporder', 		action='store_true', 			required=False, default=False,	help='keep the read ordering.')
	argparser.add_argument(	'-hm',			dest='handlemm',	metavar='N',				type=int,	required=False,	default=0,	help='Missmatches allowed in handle sequences (default 0).')
	argparser.add_argument(	'-pe',			dest='primeredit',	metavar='N',				type=int,	required=False,	default=0,	help='Editdistance allowed while identifying specific primer sequences (default 0).')
	argparser.add_argument(	'--onlydumpthreads',		dest='onlydumpthreads', 		action='store_true', 			required=False, default=False,	help='only dump the threads do not identify specifics.')	
	
	indata = argparser.parse_args(sys.argv[1:])
	
	if indata.outfile: indata.outfile = open(indata.outfile, 'w',1)
	else: indata.outfile = sys.stdout
	
	if indata.logfile: indata.logfile = open(indata.logfile, 'w',1)
	else: indata.logfile = sys.stderr
	
	if indata.sample:
		indata.outfile = open(indata.sample+'.out.txt', 'w')
		indata.logfile = open(indata.sample+'.log.txt', 'w')
		try: os.mkdir(indata.sample+'.threads')
		except OSError:pass
	
	return indata

def magicFunction(tmp):
	#unpack input and trim reads
	[pair, indata] = tmp
	
	pair.identifythreads(indata)

	for thread in pair.threads:
		thread.identifyspecific(indata,extbyseq,ext_primers,tjbyseq,tj_primers)
	
	return pair

tempo={}
#for i in range(19):
#	tempo[i]={}
#	for ID,seq in ext_primers.iteritems():
#		try:tempo[i][seq[i]].append(ID)
#		except KeyError:tempo[i][seq[i]]=[ID]
#extprimerpositions=tempo
#####
#check if run or imported // call main() or not
#####
if __name__ == "__main__":
    main()
#END of script
