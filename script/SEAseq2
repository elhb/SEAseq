#! /bin/env python

import os
import sys
MASTER = os.getpid()

man = """
    #\033[1m Pipeline for analysing "SEADseq" data: \033[0m
    # Usage: SEAseq2 <command> <path> [options]
    #
    # Available commands:
    #
    # 1. initiateAnalysis -- Initiate the analysis.
    #   Usage: SEAseq2 initiateAnalysis <path> <type>
    #   Initiation of the analysis is needed to set the path for storage of data, results and files used during runtime.
    #   During initiation the type of analysis also needs to be set either to Whole Fragment Analysis (WFA) or rRNA Amplicon Classification (RAC).
    #   
    #
    # 2. addData -- Add data to be analyzed.
    #   Usage: SEAseq2 addData <path>
    #
    # 3. changeSettings -- Define the settings to use.
    #   Usage: SEAseq2 changeSettings <path>
    #   3.1 General settings.
    #       3.1.1 Barcode sequence identification
    #       3.1.2 Barcode sequence clustering
    #       3.1.3 Parallelization - UPPMAX/LOCAL
    #       3.1.4 Subsets and debugging
    #   3.2 Settings specific for the RAC mode.
    #   3.3 Settings specific for the WFA mode.
    #   3.4 Define a none standard design.
    #        Exprimental! will most probably not work.
    #
    # 4. startAnalysis -- Start the pipe
    #   Usage: SEAseq2 startAnalysis <path> <part>
    #   Specify <part> as "all" or any of the ones included in the analysis mode (see below).
    #
    #   4.1 In any mode the pipe will perform the following parts:
    #       4.1.1 readFastqs
    #            Reads the input files, identifies subsequences within each readpair such as barcode sequences (3.1.1),
    #            primers or adapter sequences, finally adds the information to the database.
    #       4.1.2 clusterBarcodeSequences
    #            Cluster the barcode sequences identified in 4.1.1 based on sequence similarity to identify all reads originating from the same original bead.
    #
    #   4.2 In RAC mode the pipe will perform the following parts:
    #       4.2.1 findAmpliconAlleles
    #            Find all variants of amplicons present within each cluster
    #
    #   4.3 In WFA mode NOT IMPLEMENTED
    """

###############
#  Functions  #
###############

def main():
    currentRun = SEAseqPipeLine()

def bufcount(filename):
	""" returns the number of lines in a file
	"""
	import gzip
	if filename.split('.')[-1] in ['gz','gzip']: f = gzip.open(filename)
	else: f = open(filename)
	lines = 0
	buf_size = 1024 * 1024
	read_f = f.read # loop optimization
	
	buf = read_f(buf_size)
	while buf:
		lines += buf.count('\n')
		buf = read_f(buf_size)
		f.close
	return lines

def hamming_distance(s1, s2):
	assert len(s1) == len(s2), 'Error: '+str(len(s1)) + ' != ' + str(len(s2))
	return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))

def levenshtein(s1, s2):
	if len(s1) < len(s2):
		return levenshtein(s2, s1)
	if not s1:
		return len(s2)
	previous_row = xrange(len(s2) + 1)
	for i, c1 in enumerate(s1):
		current_row = [i + 1]
		for j, c2 in enumerate(s2):
			insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer
			deletions = current_row[j] + 1       # than s2
			substitutions = previous_row[j] + (c1 != c2)
			if c1 == 'N' or c2 == 'N': substitutions -= 1 #if N then no mismatch
			current_row.append(min(insertions, deletions, substitutions))
		previous_row = current_row
	return previous_row[-1]

def foreachReadPairFromFastq(pair):
    
    pair.identifyBarcode()
    pair.isIlluminaAdapter()
    
    return pair

#############
#  Classes  #
#############

class ReadPair(object):
    
    def __init__(self, currentRead, header1, header2, sequence1, sequence2, qual1, qual2,barcodeSequence,clusterId,annotations, fastq1):
	self.id = currentRead
	self.r1Header   = header1
	self.r2Header   = header2
	self.r1Seq      = sequence1
	self.r2Seq      = sequence2
	self.r1Qual     = qual1
	self.r2Qual     = qual2
	self.fileOrigin = fastq1
	self.barcodeSeq = barcodeSequence
	self.annotations= annotations    

    @property
    def databaseTuple(self, ):
	""" returning a tuple that is formated to be added to sql database"""
	# data base has following info:
	#       (id,          header,  sequence1, sequence2, quality1,quality2,barcodeSequence,clusterId,annotation,fromFastq)
	
	# Dumping the quality values
	return  (self.id,     self.r1Header,self.r1Seq,self.r2Seq,None,None,   self.barcodeSeq,None,     str(self.annotations),self.fileOrigin)

    def matchSequence(self, readsequence, matchsequence, maxDistance, matchfunk=hamming_distance):
	
	import re
	#matchfunk = hamming_distance

	startPosition = None
	endPosition   = None
	missmatches   = None

	perfect_match = re.search(matchsequence, readsequence)
	if perfect_match:
	    startPosition = perfect_match.start()
	    endPosition = perfect_match.end()
	    missmatches = 0
	
	elif int(maxDistance):
	    mindist = [10000,-1]
	    for i in range(len(readsequence)):
		
		if i+len(matchsequence) <= len(readsequence): dist = matchfunk(matchsequence,readsequence[i:i+len(matchsequence)])
		else: dist = 10001
		
		if dist < mindist[0]: mindist =[dist,i]

	    if mindist[0] < int(maxDistance)+1:
		startPosition = mindist[1]
		endPosition = mindist[1]+len(matchsequence)
		missmatches = mindist[0]
	    else:
		startPosition = None
		endPosition = None
		missmatches = None

	return [startPosition,endPosition,missmatches]

    def isIlluminaAdapter(self, ):
	
	import math
	
	for i in [15]:#range(15):
	    handleStartPosition,handleEndPosition,handleMissMatches = self.matchSequence(self.r1Seq, 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'[:35-i], int(math.ceil(float(35-i)*0.1)))
	    if handleStartPosition:
		self.annotations['Read1IsIlluminaAdapter'] = handleMissMatches
		break
	
	for i in [15]:#range(15):
	    handleStartPosition,handleEndPosition,handleMissMatches = self.matchSequence(self.r2Seq, 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT'[:34-i], int(math.ceil(float(34-i)*0.1)))
	    if handleStartPosition:
		self.annotations['Read2IsIlluminaAdapter'] = handleMissMatches
		break

    def identifyBarcode(self, ):

	handleStartPosition,handleEndPosition,handleMissMatches = self.matchSequence(self.r1Seq, SEAseqPipeLine.settings.handleSequence, SEAseqPipeLine.settings.maxHandleMissMatches)
	if handleStartPosition == SEAseqPipeLine.settings.barcodeLength:
	    self.barcodeSeq = self.r1Seq[:SEAseqPipeLine.settings.barcodeLength]
	    if handleMissMatches > 0: self.annotations['handleMissMatches'] = handleMissMatches
	    elif handleMissMatches == 0:self.annotations['handlePerfectMatch'] = True
	    else: raise ValueError, 'handleMissMatches must be integer >= 0'
	elif handleStartPosition == None: self.annotations['handleNotFound'] = True
	else: self.annotations['ErronousHandlePosition'] = handleStartPosition

    def identifyPrimerPair(self,):
	pass

class BarcodedBead(object):
    #code
    pass

class Database(object):
    
    def __init__(self, dbPath):
        self.path = dbPath
    
    def getConnection(self,):
        #
        # Import useful stuff
        #
        import sqlite3
        import sys

        #
        # Create database and set
        #
        try: self.conn = sqlite3.connect(self.path)
        except sqlite3.OperationalError:
            print 'ERROR: Trouble with the database, plase check your commandline.'
            sys.exit()
        self.c = self.conn.cursor()
    
    def commitAndClose(self,):
        #
        # commit changes and close connection
        #
        self.conn.commit()
        self.conn.close()
    
    def create(self,):
	""" creates the database holding all information used in the analysis """
	
	self.getConnection()
	
	#
	# Create tables
	#
	self.c.execute('''CREATE TABLE reads (id,header,sequence1,sequence2,quality1,quality2,barcodeSequence,clusterId,annotation,fromFastq,PRIMARY KEY (clusterId))''')
	self.c.execute('''CREATE TABLE runs (startTime,command,commandLine,finishedSuccessfully,masterPid)''')
	self.c.execute('''CREATE TABLE fastqs (filePairId,fastq1,fastq2,readCount,addedToReadsTable,minReadLength,PRIMARY KEY (filePairId))''');
	self.c.execute('''CREATE TABLE settings (variableName,defaultValue,value,setTime,PRIMARY KEY (variableName))''')
	self.c.execute('''CREATE TABLE results (resultName,value,setTime,PRIMARY KEY (resultName))''')
	
	self.commitAndClose()

    def addToRunsTable(self, startTime, command, commandLine, finishedSuccessfully, masterPid):
        
        self.getConnection()
        
        #
        # check if pid already in database
        #
        t = (masterPid,)
        data = self.c.execute('SELECT masterPid, startTime FROM runs WHERE masterPid=?',t).fetchall()        
        if data:
            for tmp1,tmp2 in data:

        #
        # if pid and startTime matches update the "finishedSuccessfully" entry
        #
                if tmp1 == masterPid and tmp2 == startTime:
                    values = (startTime, command, commandLine, finishedSuccessfully, masterPid)
                    self.c.execute('UPDATE runs SET finishedSuccessfully=? WHERE masterPid=? AND startTime=?', (finishedSuccessfully,masterPid,startTime))
        
        #
        # if not in the database add a new row
        #
        else:
            values = (startTime, command, commandLine, finishedSuccessfully, masterPid)
            self.c.execute('INSERT INTO runs VALUES (?,?,?,?,?)', values)
        
        self.commitAndClose()
        
        return 0
    
    def addFastqs(self, fastq1, fastq2):
        
        #
        # Imports
        #
        import sys
        
        #
        # open connection to database
        #
        self.getConnection()
        
        filePairId = None
        filePairIds = []
        
        #
        # check if any of the fastqs already in database
        #
        data = self.c.execute('SELECT filePairId,fastq1,fastq2 FROM fastqs').fetchall()
        if data:
            for filePair in data:
                filePairId = int(filePair[0])
                filePairIds.append(filePairId)
                for fastq in [fastq1, fastq2]:
                    if fastq in filePair:
                        message = 'ERROR: '+fastq+' already in the database.\nExiting after error.'
                        print message
                        SEAseqPipeLine.logfile.write(message+'\n')
                        sys.exit(1)
        #
        # if not in the database add a new row
        #
        SEAseqPipeLine.logfile.write('Getting readcount for file'+fastq1+' ... \n')
        readCount = bufcount(fastq1)/4 #one read is four lines
        SEAseqPipeLine.logfile.write('...done. The file has '+str(readCount)+' reads.\n')
        addedToReadsTable = False#SEAseqPipeLine.startTimeStr
        minReadLength = 'NA'

        if filePairIds: filePairId = max(filePairIds)+1
        else: filePairId = 0
        values = (filePairId,fastq1,fastq2,readCount,addedToReadsTable,minReadLength)
        self.c.execute('INSERT INTO fastqs VALUES (?,?,?,?,?,?)', values)
        
        self.commitAndClose()
        
        return 0
   
    def addReads(self, readsToAdd):

        #
        # Imports
        #
        import sys
        
        #
        # open connection to database
        #
        self.getConnection()
        
        #
        # add the data in readsToAdd to the reads table
        #

	self.c.executemany('INSERT INTO reads VALUES (?,?,?,?,?,?,?,?,?,?)', readsToAdd)
        
        self.commitAndClose()
        
        return 0

    def getFastqs(self,):
        #
        # Imports
        #
        import sys
        
        #
        # open connection to database
        #
        self.getConnection()
                
        #
        # get att data in fastqs table
        #
        filePairs = self.c.execute('SELECT filePairId,fastq1,fastq2,readCount,addedToReadsTable,minReadLength FROM fastqs').fetchall()
        
        self.commitAndClose()
        
        #return [[readCount,fastq1,fastq2] if (not addedToReadsTable) else None for filePairId,fastq1,fastq2,readCount,addedToReadsTable,minReadLength in filePairs]
	return [[readCount,fastq1,fastq2] for filePairId,fastq1,fastq2,readCount,addedToReadsTable,minReadLength in filePairs]

    def getReadPairs(self,):
        #
        # Imports
        #
        import sys
        
        #
        # open connection to database
        #
        self.getConnection()
                
        #
        # get att data in fastqs table
        #
        readPairs = self.c.execute('SELECT id,header,sequence1,sequence2,quality1,quality2,barcodeSequence,clusterId,annotation,fromFastq FROM reads')
        
	while True:
	    
	    rows = readPairs.fetchmany()#size=readPairs.arraysize)
	    
	    if not rows: break
	    
	    for row in rows:
		pairId,header,sequence1,sequence2,qual1,qual2,barcodeSequence,clusterId,annotations,fromFastq = row
		yield ReadPair(pairId, header, header, sequence1, sequence2, qual1, qual2,barcodeSequence,clusterId,eval(annotations), fromFastq)
	
        self.commitAndClose()
    
    def getRuns(self, runTypes):
        
        self.getConnection()
        
        runsInfo = []
        data = self.c.execute('SELECT * FROM runs').fetchall()
        for startTime, command, commandLine, finishedSuccessfully, masterPid in data:
            if command in runTypes: runsInfo.append([startTime, command, commandLine, finishedSuccessfully, masterPid])
        
        self.commitAndClose()
        
        return runsInfo

class Settings(object,):
    
    def __init__(self, ):
        """ object holding the settings used for each part of the analysis """
	
	self.defaultValues = {
	    'debug':False,
	    'uppmaxProject':'b2014005',
	    'parallelProcesses':16,
	    'mode':'RAC',
	    'handleSequence':'CTAAGTCCATCCGCACTCCT',
	    'maxHandleMissMatches':0,
	    'barcodeLength':15,
	    'analysisParts':None,
	    'barcodeMissmatch':0
	}
	self.explenations = {
	    'debug':'Flag for running the scripts in multiprocessing or as single process run [True/False] (default=False)',
	    'uppmaxProject':'Project id used at uppmax for sbatch scripts [bXXXXXXX] (default=b2014005)',
	    'parallelProcesses':'Number of process to run when doing multiprocess parts of analysis (defaul=16)',
	    'mode':'Type of analysis either Whole Fragment Analysis (WFA) or rRNA Amplicon Classification (RAC) [WFA/RAC] (default=RAC)',
	    'handleSequence':'The sequence that sepperate the barcode from the "specific" read sequence (default=CTAAGTCCATCCGCACTCCT)',
	    'barcodeLength':'The length of the bead barcode (default=15)',
	    'analysisParts':'Parts of the analysis to run specific for each run.',
	    'barcodeMissmatch':'Number of missmatches allowed in the barcode sequence',
	    'maxHandleMissMatches':'Number of missmatches allowed in the handle sequence'
	}
	self.isDefault = {}
	self.setTime = {}

	self.debug = None
	self.uppmaxProject = None
	self.parallelProcesses = None
	self.mode = None
	self.handleSequence = None
	self.maxHandleMissMatches = None
	self.barcodeLength = None
	self.analysisParts = None
	
	self.setDefaults()

    def setDefaults(self,):
	for variableName, value in self.defaultValues.iteritems():
	    self.__dict__[variableName] = value
	    self.isDefault[variableName] = True
	    self.setTime[variableName] = None
	return 0

    def loadFromDb(self,):
	
	#
	# Get the connection
	#
	SEAseqPipeLine.database.getConnection()
	
	#
	# Select data
	#
	data = SEAseqPipeLine.database.c.execute('SELECT variableName,defaultValue,value,setTime FROM settings').fetchall()
	
	#
	# Parse data and add to object __dict__
	#
	if data:
	    for variableName,default,value,setTime in data:
		self.__dict__[variableName]  = value
		self.isDefault[variableName] = default
		self.setTime[variableName]   = setTime
	
	#
	# close connection
	#
	SEAseqPipeLine.database.commitAndClose()

    def setVariable(self,variableName,value):
	import time
	assert variableName in self.explenations,'Error: you are trying to set an undefined variable.\n'
	self.__dict__[variableName]  = value
	self.isDefault[variableName] = False
	self.setTime[variableName]   = time.time()
	return 0

    def saveToDb(self,):
	
	#
	# imports
	#
	import time
	
	#
	# get connection
	#
	SEAseqPipeLine.database.getConnection()
	
        #
        # Look whats already in database, update it if older or default and set what is not
        #
	SEAseqPipeLine.logfile.write('checking whats in db.\n')
        alreadyInDb = {}
	data = SEAseqPipeLine.database.c.execute('SELECT variableName,defaultValue,value,setTime FROM settings').fetchall()
        if data:
            for variableName,default,value,setTime in data:
		SEAseqPipeLine.logfile.write('processing variable '+variableName+'')
		alreadyInDb[variableName] = True
		
		if variableName in self.__dict__:
		    if default and not self.isDefault[variableName] or setTime < self.setTime[variableName]:
			if type(self.__dict__[variableName]) in [dict,list]: self.__dict__[variableName] = str(self.__dict__[variableName])
			SEAseqPipeLine.logfile.write(', updating from '+str(value)+' to '+str(self.__dict__[variableName])+', old_setTime '+str(setTime)+' new_setTime '+str(self.setTime[variableName])+'.\n')
			SEAseqPipeLine.database.c.execute('UPDATE settings SET defaultValue=?, value=?, setTime=? WHERE variableName=?', (self.isDefault[variableName],self.__dict__[variableName],self.setTime[variableName],variableName))
		    else: SEAseqPipeLine.logfile.write(' no update needed.\n')
        
        #
        # Add new vars to database
        #
	SEAseqPipeLine.logfile.write('adding new vars to db:\n')
        for variableName in self.__dict__:
	    if variableName in ['explenations','defaultValues','isDefault','setTime']:continue
	    if variableName not in alreadyInDb:
		if type(self.__dict__[variableName]) in [dict,list]: self.__dict__[variableName] = str(self.__dict__[variableName])
		values = (variableName,self.isDefault[variableName],self.__dict__[variableName],self.setTime[variableName])
		SEAseqPipeLine.database.c.execute('INSERT INTO settings VALUES (?,?,?,?)', values)
		SEAseqPipeLine.logfile.write('variable '+variableName+' added to db with value '+str(self.__dict__[variableName])+',')
		if self.isDefault[variableName]:SEAseqPipeLine.logfile.write(' this is the default value.\n')
		else:SEAseqPipeLine.logfile.write(' non-default value.\n')
	    else: pass#SEAseqPipeLine.logfile.write('variable\t'+variableName+'\talready in db.\n')
        
	SEAseqPipeLine.logfile.write('commiting changes to database.\n')
        SEAseqPipeLine.database.commitAndClose()
        
        return 0

class FastqToDatabseConverter(object):
    """ reads fastq files (read one and two) and identifies the coordinates for the Barcode sequence etc and adds the data to the database """
    
    def __init__(self,):
	#
	# Setting initial values
	#
	self.filesAdded = {}
	self.readsToAdd = []
	self.currentLocation = 1
	self.appendChunkSize = 500000
        self.getFilenames()
        self.totalReadcount = 0
        self.currentRead = 0
	self.grandTotal = 0

	#
	# get the grand total readcount in all files to be added to the database
	#
	for readcount, fastq1, fastq2 in self.infiles:
	    self.grandTotal += readcount
	SEAseqPipeLine.logfile.write('Going to add a self.grandTotal of '+str(self.grandTotal)+' reads to the database.\n')

	self.progress = Progress(self.grandTotal, logfile=SEAseqPipeLine.logfile, unit='reads-post-processed', mem=True)

    def getFilenames(self,):
        self.infiles = SEAseqPipeLine.database.getFastqs()

    def readPairGenerator(self,):

	#
	# imports
	#
	import gzip

        #
        # Loop through infiles
        #
	readfromdiskProgress = Progress(self.grandTotal, logfile=SEAseqPipeLine.logfile, unit='reads-read-from-disk', mem=True)
	with readfromdiskProgress:
	    for readcount, fastq1, fastq2 in self.infiles:
		SEAseqPipeLine.logfile.write(str(self.currentRead)+' read pairs read from infiles, starting to reading from '+fastq1+'.\n')
		self.totalReadcount += readcount
		
		#
		# Open the files
		#
		if fastq1.split('.')[-1] in ['gz','gzip']: file1 = gzip.open(fastq1)
		else: file1 = open(fastq1,'r')
		if fastq2.split('.')[-1] in ['gz','gzip']: file2 = gzip.open(fastq2)
		else: file2 = open(fastq2,'r')
		
		while 'NOT EOFError':
		    try:
			header1 = file1.readline()
			header2 = file2.readline()
			sequence1 = file1.readline()
			sequence2 = file2.readline()
			trash = file1.readline()
			trash = file2.readline()
			qual1 = file1.readline()
			qual2 = file2.readline()
			if not header1: break
			self.currentRead += 1
			# data base has following info:
			#    (id,header,sequence1,sequence2,quality1,quality2,barcodeSequence,clusterId,annotation,fromFastq)
			barcodeSequence = None
			clusterId = None
			annotations = {}
			pair = ReadPair(self.currentRead, header1, header2, sequence1, sequence2, qual1, qual2,barcodeSequence,clusterId,annotations, fastq1)
			readfromdiskProgress.update()
			yield pair#self.currentRead, header1, header2, sequence1, sequence2, qual1, qual2, fastq1
		    except EOFError: break
		assert self.totalReadcount == self.currentRead, 'Error while reading infiles: Read count after file '+fastq1+' is '+str(self.currentRead)+' should theoretically be '+str(self.totalReadcount)+'.\n'
		SEAseqPipeLine.logfile.write('Reached the end of '+fastq1+'.\n')
	SEAseqPipeLine.logfile.write(str(self.grandTotal)+' read pairs read from infiles.\n')

    def foreachProcessedPair(self, pair):
	#
	# append to chunk
	#
	self.readsToAdd.append(pair.databaseTuple)

	#
	# check read pair file origin
	#
	if pair.fileOrigin not in self.filesAdded:
	    SEAseqPipeLine.logfile.write('Starting post process of read pair #'+str(pair.id)+' (from file '+pair.fileOrigin+').\n')
	    self.filesAdded[pair.fileOrigin] = True

	#
	# add chunk to db
	#
	if len(self.readsToAdd) >= self.appendChunkSize: self.chunkToDb()
	
	self.progress.update()
	
	return 0

    def chunkToDb(self, ):
	#
	# Imports
	#
	import time

	#chunkStartTime = time.time()
	chunkStartTime = time.time()
	#SEAseqPipeLine.logfile.write('Appending reads '+str(self.currentLocation)+'-'+str(self.currentLocation+self.appendChunkSize-1)+' to db.\n')
	SEAseqPipeLine.logfile.write('Staring to append reads '+str(self.currentLocation)+'-'+str(self.currentLocation+len(self.readsToAdd))+' to db.\n')

	#SEAseqPipeLine.database.addReads(self.readsToAdd)
	SEAseqPipeLine.database.addReads(self.readsToAdd)

	#chunkTime = time.time()-chunkStartTime
	chunkTime = time.time()-chunkStartTime

	#SEAseqPipeLine.logfile.write('Reads '+str(self.currentLocation)+'-'+str(self.currentLocation+self.appendChunkSize-1)+' done after '+str(int(round(chunkTime,0)/60))+' minutes and '+str(round(chunkTime,0)%60)+' seconds.\n')
	SEAseqPipeLine.logfile.write('Reads '+str(self.currentLocation)+'-'+str(self.currentLocation+len(self.readsToAdd))+' appended to db after '+str(int(round(chunkTime,0)/60))+' minutes and '+str(round(chunkTime,0)%60)+' seconds.\n')

	self.currentLocation += len(self.readsToAdd) #self.appendChunkSize

	self.readsToAdd = []
	
	return 0

    def run(self,):
	
	#
	# Write log message
	#
	SEAseqPipeLine.logfile.write('Adding reads to database table.\n')
	
	#
	# Parse through files and add to database in chunks of "self.appendChunkSize" reads
	#
	with self.progress:
	    for pair in self.readPairGenerator():
		#
		# foreach read do this before adding to db, this part could be done in parallel
		#
		pair = foreachReadPairFromFastq(pair)
		
		#
		# post procesing for each read, preparing and adding to db
		#
		self.foreachProcessedPair(pair)


	#
	# add final chunk to db
	#
	if self.readsToAdd: self.chunkToDb()
	
	#
	# Done write to log and return
	#
	SEAseqPipeLine.logfile.write('Files '+', '.join([key for key in self.filesAdded.keys()])+' added sucesfully to the database.\n')
	
	return 0

    def runParallel(self,):
	
	#
	# imports
	#
	import multiprocessing
	
	#
	# Write log message
	#
	SEAseqPipeLine.logfile.write('Adding reads to database table (working in parallel).\n')
	
	poolOfProcesses = multiprocessing.Pool(SEAseqPipeLine.settings.parallelProcesses,maxtasksperchild=100000000)
	self.parallelResults = poolOfProcesses.imap_unordered(foreachReadPairFromFastq,self.readPairGenerator(),chunksize=10000)
	
	#
	# Parse through files and add to database in chunks of "self.appendChunkSize" reads
	#
	with self.progress:
	    for pair in self.parallelResults:	    
		#
		# post procesing for each read, preparing and adding to db
		#
		self.foreachProcessedPair(pair)

	#
	# add final chunk to db
	#
	if self.readsToAdd: self.chunkToDb()
	poolOfProcesses.close()
	poolOfProcesses.join()
	
	#
	# Done write to log and return
	#
	SEAseqPipeLine.logfile.write('Files '+', '.join([key for key in self.filesAdded.keys()])+' added sucesfully to the database.\n')
	
	return 0

class SEAseqPipeLine(object):
    
    def __init__(self):
        """ Intitates the SEAseqPipeLine program run instance """
        
        #
        # imports
        #
        import time
        from socket import gethostname
        import commands
        
        #
        # Declare variables and set standard default values
        #
        SEAseqPipeLine.database = None
        self.analysisPath = None
        self.command = None
        self.commandLine = None
        self.commandLineList = None
        SEAseqPipeLine.settings = None
        SEAseqPipeLine.logfile = None
        SEAseqPipeLine.startTime = time.time()
        SEAseqPipeLine.startTimeStr = time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())
        self.availableCommands = {
            'initiateAnalysis':self.initiateAnalysis,
            'addData':self.addData,
            'changeSettings':self.changeSettings,
            'startAnalysis':self.startAnalysis,
            'commandLog':self.commandLog,
            'help':self.printHelp,
        }
        if gethostname().split('.')[1] == 'uppmax': self.onUppmax = True
        else: self.onUppmax = False
        tempFolderName = 'SEAseq2temporaryFiles'
        if self.onUppmax: self.tempFileFolder = os.path.abspath(commands.getoutput('echo $SNIC_TMP'))+'/'+tempFolderName
        else: self.tempFileFolder = self.analysisPath+'/'+tempFolderName
        if not os.path.isdir(self.tempFileFolder): os.makedirs(self.tempFileFolder)
        
        #
        # Get information from commandline
        #
        self.getComandAndPath()
        self.doCurrentTask()
    
    def doCurrentTask(self,):
        """ identifies which and starts the part of the analysis pipeline the user wants the software perform """
        
        #
        # Imports
        #
        import sys
        
        #
        # Set the database path and create the settings object
        #
        SEAseqPipeLine.database = Database(self.analysisPath+'/dataSettingsAndResults.db')
	SEAseqPipeLine.settings = Settings()
	if self.command != 'initiateAnalysis':SEAseqPipeLine.settings.loadFromDb()

        #
        # call current command
        #
        try:
            self.availableCommands[self.command].__call__()
            #except AttributeError:
            #    print 'ERROR: the command "'+self.command+'" is not implemented yet try again in the future.'
            #    sys.exit(1)
        except KeyError:
            print 'ERROR: command "'+self.command+'" is not valid.\nAvialable commands are: '+', '.join(self.availableCommands.keys()[:-1])+' and '+self.availableCommands.keys()[-1]+'.\nUse: "SEAseq2 help" to get help\n'
            return 1
    
    def printHelp(self,):
        """ prints the help message """
        print man
        return 0
    
    def commandLog(self,):
        """ print all commands performed so far """
        
        #
        # get optional arguments from commandline
        #
        self.getComandLineOptions()

        #
        # Add run to runs table and open connection to logfile
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, False, MASTER)
        self.openLogfileConnection()
        SEAseqPipeLine.logfile.write(self.createLogHeader())
        
        # default all types of commands run
        runTypes = self.availableCommands.keys()
        
        SEAseqPipeLine.logfile.write('Writing commandLog to standard out.\n')
        print 'Getting runs performed with the following commands '+', '.join(runTypes[:-1])+' or '+runTypes[-1]+'.'
        print '# StartTime:                    \tFinished:\tCommand:'
        for startTime, command, commandLine, finishedSuccessfully, masterPid in SEAseqPipeLine.database.getRuns(runTypes):
            print str(startTime)+' \t'+str(bool(finishedSuccessfully))+'      \t'+str(commandLine)
        
        #
        # update runs table
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, True, MASTER)
        
        SEAseqPipeLine.logfile.write('Finished exiting.\n')
    
    def initiateAnalysis(self,):
        """ sets the type of and path for the analysis """

        #
        # Imports
        #
        import os
        import sys

        #
        # get optional arguments from commandline
        #
        self.getComandLineOptions()
        
        #
        # for logmessages
        #
        tmpLogMessages = ['----------------\n']
        tmpLogMessage = self.createLogHeader()
        tmpLogMessages.append(tmpLogMessage)
        #print tmpLogMessage
        
        #
        # check analysis path
        #
        if os.path.isdir(self.analysisPath):
            tmpLogMessage = 'WARNING: the analysis path already exists.\n'
            print tmpLogMessage
            tmpLogMessages.append(tmpLogMessage)
        else:
            tmpLogMessage = 'Creating directory "'+self.analysisPath+'".\n'
            #print tmpLogMessage
            tmpLogMessages.append(tmpLogMessage)
            os.makedirs(self.analysisPath)
        
        #
        # create the logfile
        #
        tmpLogMessages += self.openLogfileConnection()
        
        #
        # write tmpLogMessages to logfile
        #
        SEAseqPipeLine.logfile.write(''.join(tmpLogMessages))
        
        #
        # create the database
        #
        SEAseqPipeLine.database.create()
        
        #
        # add run to runs table
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, True, MASTER)
        
        return 0
    
    def addData(self,):
        
        #
        # get optional arguments from commandline
        #
        self.getComandLineOptions()

        #
        # Add run to runs table and open connection to logfile
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, False, MASTER)
        self.openLogfileConnection()
        SEAseqPipeLine.logfile.write(self.createLogHeader())

	#
	# Add the fastq files to the database list of infiles
	#
        SEAseqPipeLine.database.addFastqs(self.fastq1,self.fastq2)

        #
        # update runs table
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, True, MASTER)
        
        SEAseqPipeLine.logfile.write('Finished exiting.\n')
    
    def changeSettings(self,):
        print 'Under development ...'
	
	#
        # get optional arguments from commandline
        #
        self.getComandLineOptions()

        #
        # Add run to runs table and open connection to logfile
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, False, MASTER)
        self.openLogfileConnection()
        SEAseqPipeLine.logfile.write(self.createLogHeader())

        #
	# update new settings
	#
	SEAseqPipeLine.settings.saveToDb()
	
	#
        # update runs table
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, True, MASTER)
        
        SEAseqPipeLine.logfile.write('Finished exiting.\n')        

    def getReadPairAnnotations(self, ):
	
	uniqAnnotations = {}
	uniqAnnotationValues = {}
	
	SEAseqPipeLine.logfile.write('Loading read annotations ...\n')
	for pair in SEAseqPipeLine.database.getReadPairs():
	    for annotation, value in pair.annotations.iteritems():
		try:            uniqAnnotations[annotation] += 1
		except KeyError:uniqAnnotations[annotation] = 1
		try:            uniqAnnotationValues[annotation+'='+str(value)] += 1
		except KeyError:uniqAnnotationValues[annotation+'='+str(value)] = 1
	SEAseqPipeLine.logfile.write('Done.\n')
	
	print '\n\n#### uniq annotations:'
	for annotation,count in uniqAnnotations.iteritems():
	    print annotation+'\t'+str(count)

	print '\n\n#### uniq annotationValues:'
	for annotation,count in uniqAnnotationValues.iteritems():
	    print annotation+'\t'+str(count)

    def clusterBarcodeSequences(self):
	print 'The clusterBarcodeSequences is not yet implemented!'
	
	uniqAnnotations = {}
	uniqAnnotationValues = {}
	uniqBarcodeSequences = {}
	
	counter = 0
	SEAseqPipeLine.logfile.write('Loading read annotations ...\n')
	for pair in SEAseqPipeLine.database.getReadPairs():
	    counter+=1
	    if counter % 100000 == 0: print counter, 'reads loaded'
	    if pair.barcodeSeq:
		try:            uniqBarcodeSequences[pair.barcodeSeq] += 1
		except KeyError:uniqBarcodeSequences[pair.barcodeSeq]  = 1
	    for annotation, value in pair.annotations.iteritems():
		try:            uniqAnnotations[annotation] += 1
		except KeyError:uniqAnnotations[annotation]  = 1
		try:            uniqAnnotationValues[annotation+'='+str(value)] += 1
		except KeyError:uniqAnnotationValues[annotation+'='+str(value)]  = 1
	SEAseqPipeLine.logfile.write('Done.\n')
	print ''
	print len(uniqBarcodeSequences),'uniq barcode sequences found in read population'

	#sort barcodes by number of reads/sequence
	import operator

	temporaryDict = {}
	for barcode, count in uniqBarcodeSequences.iteritems():
		try:		temporaryDict[count].append(barcode)
		except KeyError:temporaryDict[count] = [barcode]
	
	sortedAlleles = []
	counter = 0
	for count, barcodes in sorted(temporaryDict.iteritems(), key=operator.itemgetter(0))[::-1]:
		for barcode in barcodes:
		    print str(count)+'\t'+str(barcode)
		    counter += 1
		if counter >= 10: break
		
	print '\n\n#### uniq annotations:'
	for annotation,count in uniqAnnotations.iteritems():
	    print annotation+'\t'+str(count)

	print '\n\n#### uniq annotationValues:'
	for annotation,count in uniqAnnotationValues.iteritems():
	    print annotation+'\t'+str(count)

    def readFastqs(self,):
	#
	# Add the reads from fastq files to the database reads table
	#
	converter = FastqToDatabseConverter()
	#converter.run()
	converter.runParallel()
	SEAseqPipeLine.logfile.write('Saving settings to database.\n')
	SEAseqPipeLine.settings.saveToDb()
	SEAseqPipeLine.logfile.write('readFastqs finished.\n')

    def startAnalysis(self,):

	#
	# Imports
	#
	import time

	#
        # get optional arguments from commandline
        #
        self.getComandLineOptions()

        #
        # Add run to runs table and open connection to logfile
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, False, MASTER)
        self.openLogfileConnection()
        SEAseqPipeLine.logfile.write(self.createLogHeader())

	#
	# check parts to run and start them
	#
	for part in SEAseqPipeLine.settings.analysisParts: assert part in ['all','readFastqs','clusterBarcodeSequences'], 'Error: part '+part+' is not a valid option.\n'
	
	if 'all' in SEAseqPipeLine.settings.analysisParts or 'readFastqs' in SEAseqPipeLine.settings.analysisParts:
	    readFastqsStartTime = time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())
	    #SEAseqPipeLine.database.addToRunsTable(readFastqsStartTime, self.command+' part:readFastqs', self.commandLine, False, MASTER)
	    self.readFastqs()
	    #SEAseqPipeLine.database.addToRunsTable(readFastqsStartTime, self.command+' part:readFastqs', self.commandLine, True, MASTER)
	    
	if 'all' in SEAseqPipeLine.settings.analysisParts or 'clusterBarcodeSequences' in SEAseqPipeLine.settings.analysisParts:
	    #SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command+' part:clusterBarcodeSequences', self.commandLine, True, MASTER)
	    clusterBarcodeSequencesStartTime = time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())
	    #SEAseqPipeLine.database.addToRunsTable(clusterBarcodeSequencesStartTime, self.command+' part:clusterBarcodeSequences', self.commandLine, False, MASTER)
	    self.clusterBarcodeSequences()
	    #SEAseqPipeLine.database.addToRunsTable(clusterBarcodeSequencesStartTime, self.command+' part:clusterBarcodeSequences', self.commandLine, True, MASTER)

        #
        # update runs table
        #
        SEAseqPipeLine.database.addToRunsTable(self.startTimeStr, self.command, self.commandLine, True, MASTER)
        
        SEAseqPipeLine.logfile.write('Finished exiting.\n')        

    def openLogfileConnection(self,):
        """ open a connection to the logfile, creates a logfile if none is present """
        
        #
        # Imports
        #
        import sys
        import time
        import os
        
        #
        # for logmessages
        #        
        tmpLogMessages = []
        
        #
        # check if logfile present open connection or create
        #
        SEAseqPipeLine.logfile = self.analysisPath + '/logfile.txt'
        if os.path.isfile(SEAseqPipeLine.logfile):
            if self.command == 'initiateAnalysis':
                print 'ERROR: the logfile already exists please use another path to initiate the analysis.\n'
                sys.exit(1)
            else:
                SEAseqPipeLine.logfile = open(SEAseqPipeLine.logfile,'a',1)
                SEAseqPipeLine.logfile.write('----------------\nConnection to logfile '+SEAseqPipeLine.logfile.name+' opened.\n')
                return 0
        else:
            tmpLogMessage = 'Creating the logfile "'+SEAseqPipeLine.logfile+'".\n'
            tmpLogMessages.append(tmpLogMessage)
            print tmpLogMessage
            SEAseqPipeLine.logfile = open(SEAseqPipeLine.logfile,'w',1)
        
        return tmpLogMessages

    def getComandAndPath(self,):
        """ get the current command """

        #
        # Import packages
        #
        import re
        import sys
        import os

        #
        # get the actual info from input
        #
        self.commandLineList = sys.argv
        self.commandLine = ' '.join(sys.argv)
        try: self.command = self.commandLineList[1]
        except IndexError:
            print 'ERROR: Please supply a command.\nUse: "SEAseq2 help" to get help\n'
            sys.exit(1)

        #
        # check program name
        #
        assert self.commandLineList[0].split('/')[-1] == 'SEAseq2', 'ERROR: program name is SEAseq2 please do not rename the file.\n'

        #
        # look for help request
        #
        if re.search('^-{0,2}[hH][eE]?[lL]?[pP]?$',self.command):
            print man
            sys.exit(0)

        #
        # get the analysis path
        #
        try:
            self.analysisPath = os.path.abspath(sys.argv[2])
        except IndexError:
            print '\nERROR: please supply a path for the analysis.\nUse: "SEAseq2 help" to get help\n'
            sys.exit(1)

        return 0
    
    def getComandLineOptions(self,):
        """ function that gets the indata from the commandline """

        import argparse
        import os
        import sys
        import re
        
        indata = None
        
        #if re.search('(\ -h\ |$)|(\ --help\ |$)',self.commandLine): print man
        
        # commandLine arguments parsing
        if self.command == 'initiateAnalysis': prog = 'SEAseq2 initiateAnalysis <path> <type>'
        if self.command == 'commandLog': prog = 'SEAseq2 commandLog <path>'
        if self.command == 'addData': prog = 'SEAseq2 addData <path>'
	if self.command == 'changeSettings': prog = 'SEAseq2 changeSettings <path>'
	if self.command == 'startAnalysis': prog = 'SEAseq2 startAnalysis <path> <part>'
        argparser = argparse.ArgumentParser(prog=prog, description='', epilog='Use: "SEAseq2 help" to get more detailed help.', formatter_class=argparse.RawTextHelpFormatter)
    
        # All programs
        argparser.add_argument('--debug', dest='debug', action='store_true', required=False, help='Run the program in debug-mode, single process python script (SLOW).')
        argparser.add_argument(	'-p', dest='cpus', metavar='N',	type=int, required=False,help='The number of processes to run in parallel (default 1, current value='+str(SEAseqPipeLine.settings.parallelProcesses)+').')

        if self.command == 'commandLog':
            try: indata = argparser.parse_args(self.commandLineList[3:])
            except IndexError: pass
            
        if self.command == 'initiateAnalysis':
            try: self.mode = self.commandLineList[3]
            except IndexError:
                print 'ERROR: no analysis mode supplied.'
                sys.exit(1)
            try: indata = argparser.parse_args(self.commandLineList[4:])
            except IndexError: pass

        if self.command == 'changeSettings':
	    argparser.add_argument('-bm', dest='barcodeMissmatch', metavar='N',	type=int, required=False, help='The number of missmatches allowed in the bead barcode sequence (default 0, current value='+str(SEAseqPipeLine.settings.barcodeMissmatch)+').')
	    argparser.add_argument('-hm', dest='maxHandleMissMatches', metavar='N',	type=int, required=False, help='The number of missmatches allowed in the handle sequence (default 0, current value='+str(SEAseqPipeLine.settings.maxHandleMissMatches)+').')
	    try:
                indata = argparser.parse_args(self.commandLineList[3:])
		if indata.barcodeMissmatch != None: SEAseqPipeLine.settings.setVariable('barcodeMissmatch',indata.barcodeMissmatch)
		if indata.maxHandleMissMatches != None: SEAseqPipeLine.settings.setVariable('maxHandleMissMatches',indata.maxHandleMissMatches)
	    except IndexError: pass
    
        if self.command == 'startAnalysis':
	    argparser.add_argument('parts', metavar='<part>', type=str, nargs='+', help='parts of the analysis to perform')
            if self.onUppmax:
                argparser.add_argument('-prj','-project',dest='project',metavar='<b20xxxxx>',	type=str,	required=False,	help='uppmaxproject (default b2011011, current value='+str(SEAseqPipeLine.settings.uppmaxProject)+')')
                #argparser.add_argument('--send',	dest='send', 	action='store_true', 			required=False,	default=False,	help='Send sbatch scripts to job-queue.')
                #argparser.add_argument('--sendonly',	dest='sendonly',action='store_true', 			required=False,	default=False,	help='Do not generate the files only Send sbatch scripts to job-queue.')
                #argparser.add_argument('--small',	dest='small', 	action='store_true', 			required=False,	default=False,	help='make for smaller dataset job-queue.')
            try:
                indata = argparser.parse_args(self.commandLineList[3:])
                if indata.project != None: SEAseqPipeLine.settings.setVariable('uppmaxProject',indata.project)
		SEAseqPipeLine.settings.setVariable('analysisParts',indata.parts)
            except IndexError: pass
            
        if self.command == 'addData':
            argparser.add_argument('-r1',dest='fastq1',	metavar='FILE',type=file,required=True, help='Indata "fastq"-file read1.')
            argparser.add_argument('-r2',dest='fastq2',	metavar='FILE',type=file,required=True,	help='Indata "fastq"-file read2.')
            try:
                indata = argparser.parse_args(self.commandLineList[3:])
                self.fastq1 = os.path.abspath(indata.fastq1.name)
                self.fastq2 = os.path.abspath(indata.fastq2.name)
            except IndexError: pass
            
        if indata.debug != None: SEAseqPipeLine.settings.setVariable('debug',indata.debug)
        if indata.cpus != None:  SEAseqPipeLine.settings.setVariable('parallelProcesses',indata.cpus)

    def createLogHeader(self,):
        """ creates the header lines for each new logfile entry """
        
        #
        # Imports
        #
        import sys
        import getpass
        import commands
        from socket import gethostname
        
        #
        # get information
        #
        username = getpass.getuser()
        computer = gethostname()
        
        #
        # create the header
        #
        output = ''
        output += 'Running program: '+self.commandLine+'.\n'
        output += 'time: '+self.startTimeStr+'\n'
        output += 'Master process id='+str(MASTER)+'\n'
        output += 'Started by user = '+username+' on host = '+computer+'\n'
        if self.onUppmax: output += 'Program is run on uppmax, any temporary files will be placed in '+commands.getoutput('echo $SNIC_TMP')+' .\n'
        
        return output

class Progress():

	def __init__(self,total, verb='full', logfile=sys.stderr, unit='reads' ,mem=False, printint=0):
		import time
		self.total = total
		self.current = 0
		self.type = verb
		self.logfile = logfile
		self.ltime = time.time()
		self.lcurrent = self.current
		self.lpercentage = 0
		if verb == 'full': self.printint = 5
		elif verb == 'minimal':self.printint = 5
		self.unit = unit
		self.mem = mem
		if printint: self.printint = printint

	def __enter__(self):
		if self.type == 'minimal': self.logfile.write('0%                 50%                 100%\n')
		#                                              ....................................................................................

	def update(self):
		import time
		self.current += 1
		self.percentage = int(round(100*float(self.current)/self.total))
		if self.percentage % self.printint == 0 and self.percentage != self.lpercentage:
			self.stf=int(round((self.total-self.current)/((self.current-self.lcurrent)/(time.time()-self.ltime))))
			if self.type == 'full': self.logfile.write(
				'#Progress => '+str(self.percentage)+'%, '+
				str( round((self.current-self.lcurrent)/(time.time()-self.ltime),2) )+' '+self.unit+'/second, '+
				time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())+
				', left: '+str(self.stf/60/60)+'h '+str(self.stf/60%60)+'min '+str(self.stf%60)+'s')
			if self.mem:
				import resource
				self.logfile.write(', using '+str((resource.getrusage(resource.RUSAGE_SELF).ru_maxrss+resource.getrusage(resource.RUSAGE_CHILDREN).ru_maxrss)/1024)+' ('+str(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024)+') MB.\n')
			else:	self.logfile.write('\n')
			if self.type == 'minimal': self.logfile.write('..')
			self.ltime = time.time()
			self.lcurrent = self.current
			self.lpercentage = self.percentage

	def __exit__(self, *args):
		self.logfile.write('\n')

##############################
#  Check if run or imported  #
##############################

if __name__ == "__main__":
    main()

###################
#  END of script  #
###################