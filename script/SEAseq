#! /bin/env python
#! /usr/bin/env python2.7

###
# main wrapper will take cmdline input and run programs
###
import os
from SEAseqLib.mainLibrary import *
MASTER = os.getpid()

def main():
    import sys
    try: cmd = sys.argv[1]
    except IndexError:
	sys.stderr.write('Please specify a command, if you need help run SEAseq help.\n')
	cmd = None

    if cmd and cmd[0] not in ['H','h']: indata = getindata(cmd)
    elif not cmd: return 1
    else:	sys.stdout.write(
				    '\nProgram: SEAseq\n'
				    +'Version: ALPHA\n'
				    +'For analysis of SEAseq data.\n\n'
				    +'Usage:\tSEAseq <command> -path <analysis folder> [options]\n\n'
				    +'Commands:\n'
				    +'\tinit'		+' '.join(['' for i in range(20-len('init'))])			+'Initiate a new anlysis\n'
				    +'\taddfqs'		+' '.join(['' for i in range(20-len('addfqs'))])		+'Add fastq files to be analysed\n'
				    +'\tclusterbarcodes'+' '.join(['' for i in range(20-len('clusterbarcodes'))])	+'cluster reads according to barcode sequence\n'
				    +'\tsortreads'	+' '.join(['' for i in range(20-len('sortreads'))])		+'sort reads to barcode clusters\n'
				    +'\thelp'		+' '.join(['' for i in range(20-len('help'))])		+'print this help message and exit\n'
				    )

    if cmd == 'init':			init(indata)
    elif cmd == 'addfqs':		addfqs(indata)
    elif cmd == 'clusterbarcodes':	clusterbarcodes(indata)
    elif cmd == 'sortreads':		sortreads(indata)
    elif cmd[0] in ['H','h']:		pass
    elif cmd == None:			pass
    else: sys.stderr.write('Invalid command. Please specify a command, if you need help run SEAseq help.\n')

def sortreads(indata):

def foreachread_cluster(tmp):

    # unpack info
    pair, indata = tmp
    del tmp
    
    # convert to SEAseq readpair
    pair = SEAseqpair(pair.header, pair.r1, pair.r2)

    C_HANDLE = sequence('c handle',"CTAAGTCCATCCGCACTCCT","CTAAGTCCATCCGCACTCCT")
    pair.identify(C_HANDLE, indata)
    pair.getN15()
    
    #if indata.cid_by_bc: pair.get_cid(indata)
    
    return pair

def clusterbarcodes(indata):

    indata.outfile = initiate_file(indata.outfile, indata, mode='a')
    indata.logfile = initiate_file(indata.logfile, indata, mode='a')

    import time
    import sys
    indata.logfile.write('Running program: '+' '.join(sys.argv)+'.\n')
    indata.logfile.write('time: '+time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())+'\n')
    indata.logfile.write('Master process id='+str(MASTER)+'\n')

    indata.logfile.write('Get infiles from config-file.\n')
    indata = readConfig(indata)
    
    # get the readcount
    indata.logfile.write('Getting readcount ...\n')
    indata.numreads = 0
    for filename in indata.config['infiles']['r1']:
	tmp = bufcount(filename)/4
	indata.logfile.write(filename+' -> '+str(tmp) +' reads.\n')
	indata.numreads += tmp
    indata.logfile.write(str(indata.numreads)+' read pairs in fastq files.\n');
    # calculate the number of reads to process
    indata.reads2process = indata.numreads
    if indata.skip: indata.reads2process -= indata.skip
    if indata.stop: indata.reads2process = indata.stop
    if indata.n:    indata.reads2process = indata.n

    indata.logfile.write('Part1: identifying barcode sequences in reads.\n')
    #deciding if to run multiprocessing or single process for debugging
    if indata.debug: #single process // serial
	results=[] # create holder for processed reads
	indata.logfile.write('Running in debug mode identifying handles ...\n')
	progress = Progress(indata.reads2process, logfile=indata.logfile) # creates a progress "bar" thingy
	with progress:
	    for tmp in getPairs(indata): #itarate through reads and do the "magicFunction"
		progress.update()
		results.append(foreachread_cluster(tmp))
	indata.logfile.write('handle identification finished.\n')
    else: # multiple processes in parallel
	import multiprocessing
	#create worker pool that iterates through the reads and does the "magicFunction" and sends results to "results"
	WorkerPool = multiprocessing.Pool(indata.cpus,maxtasksperchild=1000000)
	results = WorkerPool.imap_unordered(foreachread_cluster,getPairs(indata),chunksize=100)
    if not indata.debug: indata.logfile.write('Running in multiproccessing mode using '+str(indata.cpus)+' processes  ...\n')
    else: indata.logfile.write('Running the multiprocessing results handeling in serial ... \n')
    progress = Progress(indata.reads2process, logfile=indata.logfile)
    summary = SEAseqSummary()
    with progress:
	for pair in results:
	    progress.update()
	    summary.add(pair)
    if not indata.debug:WorkerPool.close()
    if not indata.debug:WorkerPool.join()
    indata.outfile.write(str( summary.part1() )+'\n')
    indata.logfile.write('Part1: finished barcode sequences identified.\n')
    
    indata.logfile.write('Part2: Clustering the identified barcodes.\n')
    summary.reducebarcodes(indata)
    indata.logfile.write('Writing cluster info to file.\n')
    f = open(indata.path+'/clusters.tempfile','w')
    f.write(str(summary.clusters))
    f.close()
    indata.logfile.write('Part2: Clustering barcodes END\n')
    return summary

def readConfig(indata):
    indata.logfile.write('Reading config-file ...\n')
    indata.config = initiate_file(indata.path+'/'+'config',indata , mode='r')
    for line in indata.config:
	if	line.rstrip() == '# Absolute path:':	    	abspath = indata.config.next().rstrip()
	elif	line.rstrip() == '# Infiles dictionary:':	infiles = eval(indata.config.next())
    indata.config.close()
    indata.config = {'abspath':abspath,'infiles':infiles}
    return indata

def addfqs(indata):

    indata.outfile = initiate_file(indata.outfile, indata, mode='a')
    indata.logfile = initiate_file(indata.logfile, indata, mode='a')

    import time
    import sys
    indata.logfile.write('Running program: '+' '.join(sys.argv)+'.\n')
    indata.logfile.write('time: '+time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())+'\n')
    indata.logfile.write('Master process id='+str(MASTER)+'\n')

    indata.logfile.write('Reading current config ...\n')
    indata.config = initiate_file(indata.path+'/'+'config',indata , mode='r')
    before = ''
    after = ''
    for line in indata.config:
	if line.rstrip() == '# Infiles dictionary:':
	    infiles = eval(indata.config.next())
	    after = '\n'
	elif not after: before += line
	elif after:after += line
    indata.config.close()

    indata.logfile.write('Adding filenames to config file.\n')
    import os
    import sys
    r1 = os.path.abspath(indata.reads1.name)
    r2 = os.path.abspath(indata.reads2.name)
    if r1 in infiles['r1'] + infiles['r2'] or r2 in infiles['r1'] + infiles['r2']:
	sys.stderr.write('ERROR:\nat least one of the files:\n'+r1+'\n'+r2+'\nare already in the config file.\n');
	indata.logfile.write('ERROR:\nat least one of the files:\n'+r1+'\n'+r2+'\nare already in the config file.\nExiting withiout changes.\n');
	return 1
    infiles['r1'].append(r1)
    infiles['r2'].append(r2)
    indata.config = initiate_file(indata.path+'/'+'config', indata, mode='ow')
    indata.config.write(before+'# Infiles dictionary:\n'+str(infiles)+after)
    indata.config.close()
    indata.logfile.write('Files '+r1+' and '+r2+' sucessfully added to infiles dist in config.\n\n')
    indata.logfile.close()
    return 0

def init(indata):
    
    import os
    import sys
    tmp_log = ''

    if os.path.exists(indata.path+'/'+'config'):
	sys.stderr.write('This analysis has already been initiated try another command.\n')
	return
    
    try:
	os.mkdir(indata.path)
	tmp_log += 'Folder '+indata.path+' created sucessfully.\n'
    except OSError:
	_continue = ''
	while not _continue or _continue[0] not in ['Y','y', 'N','n']:
	    _continue = raw_input('WARNING: the folder '+indata.path+' already excists. Continue anyway? (yes/no) ')
	tmp_log += 'WARNING: the folder '+indata.path+' already excists. Continue anyway? (yes/no) '+_continue+'\nUsing already exsisting folder ...\n'
	if _continue[0] in ['Y','y']: pass
	elif _continue[0] in ['N','n']: return
	else:
	    sys.stderr.write('Error 1\n.'); return 1

    indata.outfile = initiate_file(indata.outfile, indata)
    indata.logfile = initiate_file(indata.logfile, indata)

    import time
    indata.logfile.write('Running program: '+' '.join(sys.argv)+'.\n')
    indata.logfile.write('time: '+time.strftime("%A, %d %b %Y %H:%M:%S",time.localtime())+'\n')
    indata.logfile.write('Master process id='+str(MASTER)+'\n')
    indata.logfile.write(tmp_log)

    indata.logfile.write('Creating config file:\n')
    indata.config = initiate_file(indata.path+'/'+'config', indata)

    abspath = os.path.abspath(indata.path)
    infiles = {'r1':[],'r2':[]}

    indata.logfile.write('Writing settings to config file ...\n')
    indata.config.write(
	'# Absolute path:\n'+abspath+'\n'+
	'# Infiles dictionary:\n'+str(infiles)+'\n'
	)

    indata.logfile.write('Analysis '+abspath+' sucesfully initiated.\n')
    return 0

def initiate_file(filename, indata, mode='w'):
    import os
    
    if type(indata.logfile) == file and mode != 'r': indata.logfile.write('Initiating '+filename+' ...\n')
    
    if mode == 'w' and os.path.exists(filename):
	tmp = filename
	filename = raw_input('WARNING: the file '+filename+' already excists. Enter an alternative filename (leave empty to overwrite):')
	if type(indata.logfile) == file and mode != 'r': indata.logfile.write('WARNING: the file '+filename+' already excists. Enter an alternative filename (leave empty to overwrite):')
	if not filename:
	    filename = tmp
	    if type(indata.logfile) == file and mode != 'r': indata.logfile.write('overwriting\n')
	#else:
	#    if type(indata.logfile) == file and mode != 'r': indata.logfile.write('Creating file '+filename+'.\n')
    
    if mode =='ow': mode ='w'
    out = open(filename, mode,1)
    
    if type(indata.logfile) == file and mode != 'r': indata.logfile.write('File '+filename+' sucessfully initiated.\n')
    
    return out

def getindata(cmd):
    import argparse
    argparser = argparse.ArgumentParser(description='Analysis of SEAseq data.', formatter_class=argparse.RawTextHelpFormatter)
    argparser.add_argument('cmd')
    argparser.add_argument(	'--debug',		dest='debug', 			action='store_true', 			required=False,	default=False,	help='Debug (run as regular single process python script).')
    argparser.add_argument('-path',	dest='path',	metavar='<path>',		type=str,required=True,	default=False,	help='Set the analysis path.')

    #argparser.add_argument(	'-o',			dest='outfile',	metavar='outfile',			type=str,	required=True,	default=False,	help='Print output to outfile.')
    #argparser.add_argument(	'-l',			dest='logfile',	metavar='logfile',			type=str,	required=False,	default=False,	help='Print log messages to logfile (default stderr).')

    if cmd == 'init': pass
    elif cmd == 'addfqs':
	argparser.add_argument(	'-r1',			dest='reads1',	metavar='FILE',				type=file,	required=True, 			help='Indata "fastq"-file read1.')
	argparser.add_argument(	'-r2',			dest='reads2',	metavar='FILE',				type=file,	required=True,	default=None,	help='Indata "fastq"-file read2.')
    elif cmd == 'clusterbarcodes':
	argparser.add_argument(	'-p',			dest='cpus',	metavar='N',				type=int,	required=False,	default=1,	help='The number of processes to run in parallel (default 1).')
	argparser.add_argument(	'-skip',		dest='skip',	metavar='N',				type=int,	required=False,	default=0,	help='Skip the first N read pairs in files (default 0).')
	argparser.add_argument(	'-stop',		dest='stop',	metavar='N',				type=int,	required=False,	default=0,	help='Stop after N read pairs, set to 0 to disable (default 0).')
	argparser.add_argument(	'-random',		dest='n',	metavar='N',				type=int,	required=False,	default=0,	help='Use a random subset of N read pairs, this option is slower (default 0 = off). Can not be used in combination with "-skip" or "-stop"')
	argparser.add_argument(	'-hm',			dest='handlemm',metavar='N',				type=int,	required=False,	default=0,	help='Number off missmatches allowed in handle sequence (default 0)')
	argparser.add_argument(	'-bm',			dest='bcmm',	metavar='N',				type=int,	required=False,	default=0,	help='Number off missmatches allowed in barcode sequence during clustering (default 0)')
        argparser.add_argument(	'-mrc',			dest='mrc',	metavar='N',				type=int,	required=False,	default=1,	help='Minimum number of reads per cluster to consider it (default 1) DISABLED: tests from 10 to 1000')
        argparser.add_argument(	'-seed',		dest='seed',	metavar='N',				type=int,	required=False,	default=100,	help='Number of top barcodes (with most reads) to use as seeds in clustering(default 100)')
    elif cmd == 'sortreads':
        argparser.add_argument(	'-sortfmt',		dest='sortfmt',	metavar='[fa/fq]',			type=str,	required=False,	default='fa',	help='Format to output reads to fa=fasta or fq=fastq (default fastq)')
	argparser.add_argument(	'-skip',		dest='skip',	metavar='N',				type=int,	required=False,	default=0,	help='Skip the first N read pairs in files (default 0).')
	argparser.add_argument(	'-stop',		dest='stop',	metavar='N',				type=int,	required=False,	default=0,	help='Stop after N read pairs, set to 0 to disable (default 0).')
	argparser.add_argument(	'-random',		dest='n',	metavar='N',				type=int,	required=False,	default=0,	help='Use a random subset of N read pairs, this option is slower (default 0 = off). Can not be used in combination with "-skip" or "-stop"')

    import sys
    indata = argparser.parse_args(sys.argv[1:])
    if indata.path[-1] == '/': indata.path=indata.path[:-1]

    indata.selftest = False
    if cmd == 'init':
	indata.outfile = indata.path + '/' + 'init.out.txt'
	indata.logfile = indata.path + '/' + 'init.log.txt'
    elif cmd == 'addfqs':
	assert indata.reads1 != indata.reads2, 'Error: read 1 and read 2 cannot be same file!\n'
	indata.outfile = indata.path + '/' + 'addfqs.out.txt'
	indata.logfile = indata.path + '/' + 'addfqs.log.txt'
    elif cmd == 'clusterbarcodes':
	indata.outfile = indata.path + '/' + 'clusterBarcodes.out.txt'
	indata.logfile = indata.path + '/' + 'clusterBarcodes.log.txt'    
    elif cmd == 'sortreads':pass

    
    #if indata.outfile: indata.outfile = open(indata.outfile, 'w',1)
    #else: indata.outfile = sys.stdout
    #
    #if indata.logfile: indata.logfile = open(indata.logfile, 'w',1)
    #else: indata.logfile = sys.stderr
    
    return indata

#####
#check if run or imported // call main() or not
#####
if __name__ == "__main__":
    main()
#END of script
